Requirement already satisfied: torch in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (2.0.1)
Requirement already satisfied: numpy in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (1.24.4)
Requirement already satisfied: transformers in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (4.30.2)
Requirement already satisfied: datasets in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (2.13.1)
Requirement already satisfied: tiktoken in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (0.4.0)
Requirement already satisfied: wandb in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (0.15.4)
Requirement already satisfied: tqdm in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (4.65.0)
Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == "Linux" and platform_machine == "x86_64" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (11.7.4.91)
Requirement already satisfied: typing-extensions in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (4.7.1)
Requirement already satisfied: networkx in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (3.1)
Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (2.10.1)
Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == "Linux" and platform_machine == "x86_64" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (10.9.0.58)
Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == "Linux" and platform_machine == "x86_64" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (10.2.10.91)
Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == "Linux" and platform_machine == "x86_64" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (8.5.0.96)
Requirement already satisfied: sympy in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (1.12)
Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == "Linux" and platform_machine == "x86_64" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (11.7.91)
Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == "Linux" and platform_machine == "x86_64" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (11.7.99)
Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == "Linux" and platform_machine == "x86_64" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (11.4.0.1)
Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == "Linux" and platform_machine == "x86_64" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (2.14.3)
Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == "Linux" and platform_machine == "x86_64" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (11.10.3.66)
Requirement already satisfied: triton==2.0.0; platform_system == "Linux" and platform_machine == "x86_64" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (2.0.0)
Requirement already satisfied: filelock in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (3.12.2)
Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == "Linux" and platform_machine == "x86_64" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (11.7.99)
Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == "Linux" and platform_machine == "x86_64" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from torch) (11.7.101)
Requirement already satisfied: regex!=2019.12.17 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from transformers) (2023.6.3)
Requirement already satisfied: safetensors>=0.3.1 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from transformers) (0.3.1)
Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.22.0)
Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from transformers) (0.13.3)
Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from transformers) (0.16.2)
Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)
Requirement already satisfied: packaging>=20.0 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from transformers) (23.1)
Requirement already satisfied: multiprocess in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from datasets) (0.70.14)
Requirement already satisfied: xxhash in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from datasets) (3.2.0)
Requirement already satisfied: dill<0.3.7,>=0.3.0 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from datasets) (0.3.6)
Requirement already satisfied: fsspec[http]>=2021.11.1 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from datasets) (2023.6.0)
Requirement already satisfied: pyarrow>=8.0.0 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from datasets) (12.0.1)
Requirement already satisfied: aiohttp in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from datasets) (3.8.4)
Requirement already satisfied: pandas in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from datasets) (2.0.3)
Requirement already satisfied: docker-pycreds>=0.4.0 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from wandb) (0.4.0)
Requirement already satisfied: Click!=8.0.0,>=7.0 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from wandb) (8.1.3)
Requirement already satisfied: psutil>=5.0.0 in /usr/lib/python3/dist-packages (from wandb) (5.5.1)
Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb) (45.2.0)
Requirement already satisfied: pathtools in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from wandb) (0.1.2)
Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0; python_version < "3.9" and sys_platform == "linux" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from wandb) (4.23.3)
Requirement already satisfied: sentry-sdk>=1.0.0 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from wandb) (1.27.0)
Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from wandb) (3.1.31)
Requirement already satisfied: setproctitle in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from wandb) (1.3.2)
Requirement already satisfied: appdirs>=1.4.3 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from wandb) (1.4.4)
Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cusparse-cu11==11.7.4.91; platform_system == "Linux" and platform_machine == "x86_64"->torch) (0.34.2)
Requirement already satisfied: mpmath>=0.19 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from sympy->torch) (1.3.0)
Requirement already satisfied: lit in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from triton==2.0.0; platform_system == "Linux" and platform_machine == "x86_64"->torch) (16.0.6)
Requirement already satisfied: cmake in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from triton==2.0.0; platform_system == "Linux" and platform_machine == "x86_64"->torch) (3.26.4)
Requirement already satisfied: frozenlist>=1.1.1 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)
Requirement already satisfied: multidict<7.0,>=4.5 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)
Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)
Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from aiohttp->datasets) (3.1.0)
Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets) (19.3.0)
Requirement already satisfied: aiosignal>=1.1.2 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)
Requirement already satisfied: yarl<2.0,>=1.0 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)
Requirement already satisfied: tzdata>=2022.1 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from pandas->datasets) (2023.3)
Requirement already satisfied: pytz>=2020.1 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from pandas->datasets) (2023.3)
Requirement already satisfied: python-dateutil>=2.8.2 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)
Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.14.0)
Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from sentry-sdk>=1.0.0->wandb) (2019.11.28)
Requirement already satisfied: urllib3>=1.26.11; python_version >= "3.6" in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from sentry-sdk>=1.0.0->wandb) (2.0.3)
Requirement already satisfied: gitdb<5,>=4.0.1 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)
Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (2.8)
Requirement already satisfied: smmap<6,>=3.0.1 in /orfeo/cephfs/home/dssc/valinsogna/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Overriding config with config/finetune_whatsapp.py:
import time

out_dir = 'out-whatsapp_finetune'
eval_interval = 5
eval_iters = 40
wandb_log = False # feel free to turn on
wandb_project = 'out-whatsapp_finetune'
wandb_run_name = 'ft-' + str(time.time())

dataset = 'whatsapp'
init_from = 'gpt2-xl' # this is the largest GPT-2 model

# only save checkpoints if the validation loss improves
always_save_checkpoint = False

# the number of examples per iter:
# 1 batch_size * 32 grad_accum * 1024 tokens = 32,768 tokens/iter
# shakespeare has 301,966 tokens, so 1 epoch ~= 9.2 iters
batch_size = 1
gradient_accumulation_steps = 32
max_iters = 20

# finetune at constant LR
learning_rate = 3e-5
decay_lr = False
Overriding config with config/finetune_whatsapp.py:
import time

out_dir = 'out-whatsapp_finetune'
eval_interval = 5
eval_iters = 40
wandb_log = False # feel free to turn on
wandb_project = 'out-whatsapp_finetune'
wandb_run_name = 'ft-' + str(time.time())

dataset = 'whatsapp'
init_from = 'gpt2-xl' # this is the largest GPT-2 model

# only save checkpoints if the validation loss improves
always_save_checkpoint = False

# the number of examples per iter:
# 1 batch_size * 32 grad_accum * 1024 tokens = 32,768 tokens/iter
# shakespeare has 301,966 tokens, so 1 epoch ~= 9.2 iters
batch_size = 1
gradient_accumulation_steps = 32
max_iters = 20

# finetune at constant LR
learning_rate = 3e-5
decay_lr = False
Overriding config with config/finetune_whatsapp.py:
import time

out_dir = 'out-whatsapp_finetune'
eval_interval = 5
eval_iters = 40
wandb_log = False # feel free to turn on
wandb_project = 'out-whatsapp_finetune'
wandb_run_name = 'ft-' + str(time.time())

dataset = 'whatsapp'
init_from = 'gpt2-xl' # this is the largest GPT-2 model

# only save checkpoints if the validation loss improves
always_save_checkpoint = False

# the number of examples per iter:
# 1 batch_size * 32 grad_accum * 1024 tokens = 32,768 tokens/iter
# shakespeare has 301,966 tokens, so 1 epoch ~= 9.2 iters
batch_size = 1
gradient_accumulation_steps = 32
max_iters = 20

# finetune at constant LR
learning_rate = 3e-5
decay_lr = False
Overriding config with config/finetune_whatsapp.py:
import time

out_dir = 'out-whatsapp_finetune'
eval_interval = 5
eval_iters = 40
wandb_log = False # feel free to turn on
wandb_project = 'out-whatsapp_finetune'
wandb_run_name = 'ft-' + str(time.time())

dataset = 'whatsapp'
init_from = 'gpt2-xl' # this is the largest GPT-2 model

# only save checkpoints if the validation loss improves
always_save_checkpoint = False

# the number of examples per iter:
# 1 batch_size * 32 grad_accum * 1024 tokens = 32,768 tokens/iter
# shakespeare has 301,966 tokens, so 1 epoch ~= 9.2 iters
batch_size = 1
gradient_accumulation_steps = 32
max_iters = 20

# finetune at constant LR
learning_rate = 3e-5
decay_lr = False
Overriding config with config/finetune_whatsapp.py:
import time

out_dir = 'out-whatsapp_finetune'
eval_interval = 5
eval_iters = 40
wandb_log = False # feel free to turn on
wandb_project = 'out-whatsapp_finetune'
wandb_run_name = 'ft-' + str(time.time())

dataset = 'whatsapp'
init_from = 'gpt2-xl' # this is the largest GPT-2 model

# only save checkpoints if the validation loss improves
always_save_checkpoint = False

# the number of examples per iter:
# 1 batch_size * 32 grad_accum * 1024 tokens = 32,768 tokens/iter
# shakespeare has 301,966 tokens, so 1 epoch ~= 9.2 iters
batch_size = 1
gradient_accumulation_steps = 32
max_iters = 20

# finetune at constant LR
learning_rate = 3e-5
decay_lr = False
Overriding config with config/finetune_whatsapp.py:
import time

out_dir = 'out-whatsapp_finetune'
eval_interval = 5
eval_iters = 40
wandb_log = False # feel free to turn on
wandb_project = 'out-whatsapp_finetune'
wandb_run_name = 'ft-' + str(time.time())

dataset = 'whatsapp'
init_from = 'gpt2-xl' # this is the largest GPT-2 model

# only save checkpoints if the validation loss improves
always_save_checkpoint = False

# the number of examples per iter:
# 1 batch_size * 32 grad_accum * 1024 tokens = 32,768 tokens/iter
# shakespeare has 301,966 tokens, so 1 epoch ~= 9.2 iters
batch_size = 1
gradient_accumulation_steps = 32
max_iters = 20

# finetune at constant LR
learning_rate = 3e-5
decay_lr = False
Overriding config with config/finetune_whatsapp.py:
import time

out_dir = 'out-whatsapp_finetune'
eval_interval = 5
eval_iters = 40
wandb_log = False # feel free to turn on
wandb_project = 'out-whatsapp_finetune'
wandb_run_name = 'ft-' + str(time.time())

dataset = 'whatsapp'
init_from = 'gpt2-xl' # this is the largest GPT-2 model

# only save checkpoints if the validation loss improves
always_save_checkpoint = False

# the number of examples per iter:
# 1 batch_size * 32 grad_accum * 1024 tokens = 32,768 tokens/iter
# shakespeare has 301,966 tokens, so 1 epoch ~= 9.2 iters
batch_size = 1
gradient_accumulation_steps = 32
max_iters = 20

# finetune at constant LR
learning_rate = 3e-5
decay_lr = False
Overriding config with config/finetune_whatsapp.py:
import time

out_dir = 'out-whatsapp_finetune'
eval_interval = 5
eval_iters = 40
wandb_log = False # feel free to turn on
wandb_project = 'out-whatsapp_finetune'
wandb_run_name = 'ft-' + str(time.time())

dataset = 'whatsapp'
init_from = 'gpt2-xl' # this is the largest GPT-2 model

# only save checkpoints if the validation loss improves
always_save_checkpoint = False

# the number of examples per iter:
# 1 batch_size * 32 grad_accum * 1024 tokens = 32,768 tokens/iter
# shakespeare has 301,966 tokens, so 1 epoch ~= 9.2 iters
batch_size = 1
gradient_accumulation_steps = 32
max_iters = 20

# finetune at constant LR
learning_rate = 3e-5
decay_lr = False
tokens per iteration will be: 32,768
tokens per iteration will be: 32,768
tokens per iteration will be: 32,768
tokens per iteration will be: 32,768
tokens per iteration will be: 32,768
tokens per iteration will be: 32,768
tokens per iteration will be: 32,768
Initializing from OpenAI GPT-2 weights: gpt2-xlInitializing from OpenAI GPT-2 weights: gpt2-xlInitializing from OpenAI GPT-2 weights: gpt2-xlInitializing from OpenAI GPT-2 weights: gpt2-xlInitializing from OpenAI GPT-2 weights: gpt2-xlInitializing from OpenAI GPT-2 weights: gpt2-xl
Initializing from OpenAI GPT-2 weights: gpt2-xl





tokens per iteration will be: 32,768
Initializing from OpenAI GPT-2 weights: gpt2-xl
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (5.1.0) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (5.1.0) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (5.1.0) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (5.1.0) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (5.1.0) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (5.1.0) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (5.1.0) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (5.1.0) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
loading weights from pretrained gpt: gpt2-xlloading weights from pretrained gpt: gpt2-xl

forcing vocab_size=50257, block_size=1024, bias=Trueforcing vocab_size=50257, block_size=1024, bias=True

overriding dropout rate to 0.0overriding dropout rate to 0.0

loading weights from pretrained gpt: gpt2-xlloading weights from pretrained gpt: gpt2-xlloading weights from pretrained gpt: gpt2-xl


forcing vocab_size=50257, block_size=1024, bias=Trueforcing vocab_size=50257, block_size=1024, bias=True

forcing vocab_size=50257, block_size=1024, bias=Trueoverriding dropout rate to 0.0
overriding dropout rate to 0.0

overriding dropout rate to 0.0
loading weights from pretrained gpt: gpt2-xl
forcing vocab_size=50257, block_size=1024, bias=True
overriding dropout rate to 0.0
loading weights from pretrained gpt: gpt2-xl
loading weights from pretrained gpt: gpt2-xlforcing vocab_size=50257, block_size=1024, bias=True

forcing vocab_size=50257, block_size=1024, bias=Trueoverriding dropout rate to 0.0

overriding dropout rate to 0.0
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 4148041 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 4148042 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 4148044 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 4148045 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 4148048 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -9) local_rank: 2 (pid: 4148043) of binary: /usr/bin/python3
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (5.1.0) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Traceback (most recent call last):
  File "/u/dssc/valinsogna//.local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/u/dssc/valinsogna/.local/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/u/dssc/valinsogna/.local/lib/python3.8/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/u/dssc/valinsogna/.local/lib/python3.8/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/u/dssc/valinsogna/.local/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/u/dssc/valinsogna/.local/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
train.py FAILED
--------------------------------------------------------
Failures:
[1]:
  time      : 2023-07-08_12:20:06
  host      : dgx001.hpc
  rank      : 5 (local_rank: 5)
  exitcode  : -9 (pid: 4148046)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 4148046
[2]:
  time      : 2023-07-08_12:20:06
  host      : dgx001.hpc
  rank      : 6 (local_rank: 6)
  exitcode  : -9 (pid: 4148047)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 4148047
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-07-08_12:20:06
  host      : dgx001.hpc
  rank      : 2 (local_rank: 2)
  exitcode  : -9 (pid: 4148043)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 4148043
========================================================
slurmstepd: error: Detected 3 oom-kill event(s) in StepId=16980.batch. Some of your processes may have been killed by the cgroup out-of-memory handler.
